{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Timesofindia_Prediction_of_News.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP64Qh33n+ifEE/uGqKzg6d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LT-O0mUWeR8U","executionInfo":{"status":"ok","timestamp":1660968684554,"user_tz":-345,"elapsed":31244,"user":{"displayName":"Vijay Yadav","userId":"04606611356925954399"}},"outputId":"1bed58c5-0825-43f0-c133-911ac2ff864b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 18.5 MB 349 kB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","panel 0.12.1 requires bokeh<2.4.0,>=2.3.0, but you have bokeh 2.4.3 which is incompatible.\u001b[0m\n","\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.1.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=e116a94a169930667852ae18985c3c07f4d76e99bf34441c42bf5f480f01db47\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built sklearn\n","Installing collected packages: sklearn\n","Successfully installed sklearn-0.0\n"]}],"source":["# This cell connects to google drive, authenticates connection, and iterates over file list displaying each file's title and ID.\n","# it also imports and installs all the necessary libraries\n","!pip install -U -q PyDrive\n","!pip install -U -q wordcloud\n","!pip install -U -q bokeh\n","!pip install textblob\n","!pip install sklearn\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from bs4 import BeautifulSoup\n","\n","from wordcloud import WordCloud\n","from scipy.stats import hmean\n","from scipy.stats import norm\n","from pylab import *\n","from bokeh.plotting import figure\n","from bokeh.io import output_notebook, show\n","from bokeh.models import LinearColorMapper\n","from bokeh.models import HoverTool\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","\n","from textblob import TextBlob\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score\n","\n","from time import time\n","\n","  "]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDXE8Oc-edgq","executionInfo":{"status":"ok","timestamp":1660019290508,"user_tz":-345,"elapsed":23851,"user":{"displayName":"Vijay Yadav","userId":"04606611356925954399"}},"outputId":"70364259-40f4-4487-e301-b62eb6103f41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Colab Notebooks/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDCZUDhCedj3","executionInfo":{"status":"ok","timestamp":1660019293000,"user_tz":-345,"elapsed":744,"user":{"displayName":"Vijay Yadav","userId":"04606611356925954399"}},"outputId":"39b63b6c-38ab-49c8-9ed7-00a9d99a69fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["!pip install spacy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-YFUhXzedm7","executionInfo":{"status":"ok","timestamp":1660019299470,"user_tz":-345,"elapsed":3947,"user":{"displayName":"Vijay Yadav","userId":"04606611356925954399"}},"outputId":"0206fcab-ce3f-44a5-f4da-1f5d7394a3c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"]}]},{"cell_type":"code","source":["def predict_aspect(text):\n","  # Importing the required libraries\n","  import spacy\n","  sp = spacy.load(\"en_core_web_sm\")\n","  from textblob import TextBlob\n","\n","  # Creating a list of positive and negative sentences.\n","  mixed_sen = [text]\n","\n","  # An empty list for obtaining the extracted aspects\n","  # from sentences.\n","  ext_aspects = []\n","\n","  # Performing Aspect Extraction\n","  for sen in mixed_sen:\n","    important = sp(sen)\n","    descriptive_item = ''\n","    target = ''\n","    for token in important:\n","      if token.dep_ == 'nsubj' and token.pos_ == 'NOUN':\n","        target = token.text\n","      if token.pos_ == 'ADJ':\n","        added_terms = ''\n","        for mini_token in token.children:\n","          if mini_token.pos_ != 'ADV':\n","            continue\n","          added_terms += mini_token.text + ' '\n","        descriptive_item = added_terms + token.text \n","    ext_aspects.append({'aspect': target,'description': descriptive_item})\n","\n","  print(\"ASPECT EXTRACTION\\n\")\n","  print(ext_aspects)\n","\n","\n","  for aspect in ext_aspects:\n","    aspect['sentiment'] = TextBlob(aspect['description']).sentiment\n","\n","  print(\"\\n\")\n","  print(\"\\nSENTIMENT ASSOCIATION\\n\")\n","  print(ext_aspects)\n"],"metadata":{"id":"K4dIm11yfpM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model"],"metadata":{"id":"oQYe9laFg76H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading\n","with open('tokenizer_sentiment.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)"],"metadata":{"id":"YCaHhAhojgZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load model\n","\n","def predict_sentiment(text):\n","    '''Function to predict sentiment class of the passed text'''\n","    model = load_model('timesofindia_lstm_model_for_sentiment.h5')\n","\n","    sentiment_classes = ['Negative', 'Positive']\n","    max_len=50\n","    \n","    # Transforms text to a sequence of integers using a tokenizer object\n","    xt = tokenizer.texts_to_sequences(text)\n","    # Pad sequences to the same length\n","    xt = pad_sequences(xt, padding='post', maxlen=max_len)\n","    # Do the prediction using the loaded model\n","    yt = model.predict(xt).argmax(axis=1)\n","    # Print the predicted sentiment\n","    print('The predicted sentiment is', sentiment_classes[yt[0]])\n","\n","    \n","\n","    \n","\n","   "],"metadata":{"id":"k0NWr8J9fpPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","\n","# Load model\n","model = load_model('timesofindia_lstm_model_for_topic.h5')\n","\n","def predict_topic(text):\n","    '''Function to predict Topic class of the passed text'''\n","    model = load_model('timesofindia_lstm_model_for_topic.h5')\n","\n","    topic_classes = ['Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5', 'Topic 6', 'Topic 7', 'Topic 8', 'Topic 9', 'Topic 10', 'Topic 11', 'Topic 12','Topic 13', 'Topic 14', 'Topic 15', 'Topic 16', 'Topic 17', 'Topic 18', 'Topic 19', 'Topic 20', 'Topic 21', 'Topic 22', 'Topic 23', 'Topic 24']\n","    max_len=50\n","    \n","    # Transforms text to a sequence of integers using a tokenizer object\n","    xt = tokenizer.texts_to_sequences(text)\n","    # Pad sequences to the same length\n","    xt = pad_sequences(xt, padding='post', maxlen=max_len)\n","    # Do the prediction using the loaded model\n","    yt = model.predict(xt).argmax(axis=1)\n","    # Print the predicted sentiment\n","    print('\\nThe predicted Topic is', topic_classes[yt[0]])\n","\n","    \n","\n","    #for apspect based sentiment prediction\n","    # converting list to string type\n","    str1 = \" \" \n","    \n","    # return string  \n","    txt= str1.join(text)\n","    predict_aspect(txt)\n","\n","   "],"metadata":{"id":"gHUZqNjTqMw7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_sent_topic(text):\n","  get_txt=text\n","\n","  predict_sentiment(get_txt)\n","  predict_topic(get_txt)\n","\n","\n"],"metadata":{"id":"SCHj6gKYqlPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_sent_topic(['The bomb on plane threat creates flutter at Bengaluru airport'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sh7hPYgfpSP","executionInfo":{"status":"ok","timestamp":1660019764498,"user_tz":-345,"elapsed":4614,"user":{"displayName":"Vijay Yadav","userId":"04606611356925954399"}},"outputId":"ea3366bd-4abc-4527-e945-b2f03856f30b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The predicted sentiment is Negative\n","\n","The predicted Topic is Topic 10\n","ASPECT EXTRACTION\n","\n","[{'aspect': 'bomb', 'description': ''}]\n","\n","\n","\n","SENTIMENT ASSOCIATION\n","\n","[{'aspect': 'bomb', 'description': '', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}]\n"]}]},{"cell_type":"code","source":["predict_sent_topic(['India to see major growth in manufacturing sector in the year 2022'])"],"metadata":{"id":"_LlhE0lfsQeF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660019893079,"user_tz":-345,"elapsed":5416,"user":{"displayName":"Vijay Yadav","userId":"04606611356925954399"}},"outputId":"eb9da9d9-46ec-41d6-8a96-b408164598f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The predicted sentiment is Positive\n","\n","The predicted Topic is Topic 3\n","ASPECT EXTRACTION\n","\n","[{'aspect': '', 'description': 'major'}]\n","\n","\n","\n","SENTIMENT ASSOCIATION\n","\n","[{'aspect': '', 'description': 'major', 'sentiment': Sentiment(polarity=0.0625, subjectivity=0.5)}]\n"]}]},{"cell_type":"code","source":["predict_sent_topic(['ISROs sslv missile launch failed'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kfVkbqb5yGE","executionInfo":{"status":"ok","timestamp":1660020342348,"user_tz":-345,"elapsed":4822,"user":{"displayName":"Vijay Yadav","userId":"04606611356925954399"}},"outputId":"d42a6c0d-287b-4ccb-e4c6-56870158e344"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The predicted sentiment is Negative\n","\n","The predicted Topic is Topic 15\n","ASPECT EXTRACTION\n","\n","[{'aspect': 'launch', 'description': ''}]\n","\n","\n","\n","SENTIMENT ASSOCIATION\n","\n","[{'aspect': 'launch', 'description': '', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"pZFZRhSY5yQg"},"execution_count":null,"outputs":[]}]}